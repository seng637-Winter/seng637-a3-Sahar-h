**SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report #3 â€“ Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      | 15 |
| -------------- | --- |
| Student Names: |Mehrnaz Senobari|
|                |Sina Salimian|
|                |Sahar Hajjar Zadeh|
|                |Zar Safari|
|                |Fatemeh Ghaffarpour|
|                |Alireza Esmaeili|

# 1. Introduction
White-box testing is a way of checking software where we look inside the code itself, unlike black-box testing, which only looks at what the software does from the outside. With white-box testing, we can see exactly which parts of the code the tests are checking and which parts they're not.

This kind of testing is really useful because it lets us make sure that all the different parts of the code are tested. We can find problems or parts of the code that might not work right under certain conditions.

We're using white-box testing on a project called JFreeChart. JFreeChart is a tool that lets people add charts, like bar graphs or pie charts, to their Java applications easily. We already started testing JFreeChart in our last assignment, and now we want to do even more tests to make sure we cover more of the code.

When we talk about covering more of the code, we're talking about "code coverage." Code coverage is just a way to measure how much of the code we have tested. There are a few different ways to measure this:

**1. Statement Coverage:** This checks if we've tested every part of the code.

**2. Branch Coverage:** This makes sure we've tested every possible path or choice in the code, like all the "if" and "else" decisions.
**3. Condition Coverage:** This goes deeper into the decisions and checks every possible true or false condition.

**4. Path Coverage:** This is the most detailed, checking every single way we could go through the code when it runs.

By using these measures on the JFreeChart project, we want to make our tests better and make sure the JFreeChart tool works well and reliably for everyone who uses it.


# 2. Manual data-flow coverage calculations for X and Y methods

# 3. A detailed description of the testing strategy for the new unit test

# 4. A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

# 5. A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

# 6. Pros and Cons of coverage tools used and Metrics you report

# 7. A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation
| Criteria | Requirements-Based Test Generation | Coverage-Based Test Generation |
|----------|------------------------------------|--------------------------------|
| **Focus** | User needs and software functionality as defined by requirements. | Internal structure and logic of the code. |
| **Advantages** | - Directly tied to user expectations.<br>- Easier to communicate with non-technical stakeholders.<br>- Can cover a wide range of user scenarios. | - Ensures thoroughness by testing more code paths.<br>- Provides clear metrics for test completeness.<br>- Helps optimize the test suite and identify dead code. |
| **Disadvantages** | - May miss defects not apparent in requirements.<br>- Sensitive to changes in requirements.<br>- Assumes requirements are complete and accurate. | - Might overlook user-focused scenarios.<br>- Requires deeper knowledge of the codebase.<br>- High coverage doesn't guarantee all functional scenarios are tested. |
| **Best Used For** | Validating that the software meets the specified requirements and behaves as expected from a user's perspective. | Identifying hidden bugs within the code's logic and structure, and ensuring as much code as possible is tested. |
| **Maintenance and Flexibility** | Can be challenging to maintain with frequently changing requirements. | Requires regular updates to maintain high coverage as the code evolves. |
| **Complexity for Testers** | Generally lower, as it focuses on external behavior rather than internal logic. | Higher, due to the need for understanding the codebase and internal logic. |
| **Risk of Overemphasis** | Risk of focusing too much on specified requirements, potentially missing out-of-scope scenarios. | Risk of aiming for high coverage numbers at the expense of meaningful testing. |

# 8. A discussion on how the team work/effort was divided and managed

Our main goals in managing and dividing the work were to make sure everyone worked together and to keep our work consistent, even though we all have different ideas and backgrounds. Here's how we did it:

- We held group meetings to share our different ideas and agree on the best approach.
- We wrote down the team's decisions to make sure we all followed the same standards.
- We worked in pairs or as a group on some tasks to share knowledge and make sure we were all on the same page.

# 9. Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

# 10. Comments/feedback on the lab itself
